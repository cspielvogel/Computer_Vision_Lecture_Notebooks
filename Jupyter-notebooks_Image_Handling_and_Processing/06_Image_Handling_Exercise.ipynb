{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Image Handling & Processing\n",
    "\n",
    "Read through the description of the exercises and select appropriate tools / libraries. Implement the solution below the respective exercise description. Feel free to use the internet, especially the documentation of the presented libraries may be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.1\n",
    "Edge detectors can be a useful tool to identify features within an image. For example, the resulting features can later be used in a machine learning anaylsis to create a predictive model which associates certain edge patterns to outcome values such as the identification of a car in an image. Oftentimes, some data preparation is needed before conducting any kind of feature extraction. This may include steps such as conversion to gray scale and application of blurring filters to reduce noise. In the following exercise you will perform an edge detector based feature extraction including preprocessing.\n",
    "\n",
    "* Load the image \"taipei101.jpg\" from the folder \"Data\"\n",
    "* Verify that the image loading was successful\n",
    "* Resize the image to half of its original size, convert it to gray scale and apply any blur filter\n",
    "* Design a filter which is able to capture horizontal edges\n",
    "* Create a numpy array which represents the designed filter\n",
    "* Create a vertical filter by rotating the horizontal filter by 90 degrees\n",
    "* Apply the two filters to the preprocessed image\n",
    "* Display the resized version of the original image and the two filtered images simultaneously to visually compare them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Your implementation comes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2\n",
    "\n",
    "Have a look at the image where the vertical filter has been applied. Note that the filter you used only captues one of the two vertical sides of the skyscraper. This results from the fact that an edge detection filter only captures pixel intensity gradients from either low-to-high or high-to-low. In the following exercise, you will implement a solution to detect both gradients directions using edge detectors.\n",
    "\n",
    "* Design another horizontal filter which captures the reverse gradient of pixel intensities compared to your initial horizontal filter and create a numpy array representing the filter\n",
    "* Do the same for the vertical filter\n",
    "* Merge the two images resulting from the application of the horizontal filters in the same channel (gray). Repeat the same for the images generated by applying the vertical filters\n",
    "* Also, merge the two images along any of the two color channels\n",
    "* Display all four merged images simultaneously to visually compare them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Your implementation comes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "\n",
    "When performing computer vision tasks using traditional techniques, features are extracted from images and usually stored in a tabular data format. In this exercise, you will be supplied with a table containing already extracted image features belonging to two groups. You will visualize some information on the extracted features on order to find hints on the most discriminative feature in the image groups.\n",
    "\n",
    "* Go to the folder \"Data\" using your file explorer\n",
    "* Have a look at the CSV file \"metastasis.csv\" in order to understand its formatting\n",
    "* Load the table to jupyter notebook\n",
    "* Display the table to check whether the loading worked as intended\n",
    "* Count the samples belonging to each group in the \"Metastasis\" column\n",
    "* Select a visualization technique which allows you to plot the distribution of values for a feature\n",
    "* Create four plots, one for each feature (\"Sphericity\", \"Homogeneity\", \"Age\", \"HER2_mutation\"). Use the selected visualization technique to display the overlap of distributions for the two groups (\"positive\" and \"negative\") at each feature\n",
    "* Judging from the plots only, which feature is most likely to be able to differentiate between samples of group \"positive\" and \"negative\" in the \"Metastasis\" column when using 1 splitting point for separation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your implementation comes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

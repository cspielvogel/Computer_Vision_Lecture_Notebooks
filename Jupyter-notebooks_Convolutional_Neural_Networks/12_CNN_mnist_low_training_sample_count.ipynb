{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "   #### Computer Vision Winter Semester 2020/2021 by Clemens Spielvogel\n",
    "      \n",
    "In the following code example a classification model for the MNIST data is built. Only few training data is used to demonstrate the increased performance provided by data augmentation in the next jupyter notebook (13)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" # If you want to use TF CPU version while having the GPU version installed\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import Sequential, layers, regularizers\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.offline as ply\n",
    "import plotly.graph_objs as graphs\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeding random number generators to obtain reproducible results\n",
    "seed_value = 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value) # Resets itself on every use!\n",
    "tf.random.set_seed(seed_value) # tf.set_random_seed(seed_value) on older TF versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    # Load CSV file to pandas data frame\n",
    "    df = pd.read_csv(file_path, header=0)\n",
    "\n",
    "    # Split data frame columns into features and labels\n",
    "    y = df[\"label\"].values\n",
    "    X_flat = df.drop(\"label\", axis=1).values\n",
    "    X = [np.resize(array, (28, 28)) for array in X_flat] # Resize flat vector to 28x28\n",
    "    X = np.array([np.reshape(sample, (sample.shape[0], sample.shape[1], 1)) for sample in X]) # Add color channel\n",
    "    \n",
    "    return X, keras.utils.to_categorical(y) # Labels are returned as one-hot encoded vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_performances(performances, metric=\"Accuracy\", show=True):\n",
    "    \"\"\"Plot training vs. testing accuracy over all epochs. performances is a dictionary mapping epoch numbers\n",
    "       as integers to lists containing training and validation performance (e.g. accuracy).\n",
    "       metric is a string indicating the used performance metric.\"\"\"\n",
    "    x = list(performances.keys())     # Number of epoch\n",
    "    y_train = [i[0] for i in performances.values()]\n",
    "    y_val = [i[1] for i in performances.values()]\n",
    "\n",
    "    trace_train = graphs.Scatter(x=x, y=y_train, name=\"Training\", mode=\"lines+markers\",\n",
    "                                 line=dict(width=4),\n",
    "                                 marker=dict(symbol=\"circle\",\n",
    "                                             size=10))\n",
    "    trace_val = graphs.Scatter(x=x, y=y_val, name=\"Validation\", mode=\"lines+markers\",\n",
    "                                line=dict(width=4),\n",
    "                                marker=dict(symbol=\"circle\",\n",
    "                                            size=10))\n",
    "\n",
    "    layout = graphs.Layout(title=\"Training vs. Validation {}\".format(metric),\n",
    "                           xaxis={\"title\": \"Epoch\"},\n",
    "                           yaxis={\"title\": metric})\n",
    "\n",
    "    fig = graphs.Figure(data=[trace_train, trace_val], layout=layout)\n",
    "    ply.plot(fig, filename=\"plotly_train_val_{}.html\".format(metric), auto_open=show)\n",
    "    print(\"Plot saved as plotly_train_val_{}.html\".format(metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_2DCNN_model(input_shape):\n",
    "    \"\"\"Build architecture of the model\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), input_shape=input_shape,\n",
    "                            activation=\"relu\", padding=\"same\"))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=\"selu\", padding=\"same\"))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=\"selu\", padding=\"same\"))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=\"selu\", padding=\"same\"))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation=\"selu\", padding=\"same\"))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation=\"selu\",\n",
    "                           kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(32, activation=\"selu\"))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    # Create model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify data location\n",
    "data_dir = r\"Data\\mnist.csv\"\n",
    "\n",
    "# Set hyperparameters\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "dims = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X, y = load_data(data_dir)\n",
    "\n",
    "# Determine split sizes (Could also be hardcoded)\n",
    "train_size = math.floor(0.02 * len(y))  # ONLY 2 % of the data set is used for training to demonstrate the augmentation benefit\n",
    "val_size = math.floor(0.49 * len(y))\n",
    "test_size = math.floor(0.49 * len(y))\n",
    "\n",
    "# Create splitted sets\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]\n",
    "X_test, y_test = X[train_size+val_size:], y[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN model\n",
    "model = create_2DCNN_model(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure stopping criterion via early stopping\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 4900 samples\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 10.9522 - accuracy: 0.0850 - val_loss: 3.2980 - val_accuracy: 0.1633\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 4.1512 - accuracy: 0.1500 - val_loss: 2.8146 - val_accuracy: 0.2027\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 3.2469 - accuracy: 0.2250 - val_loss: 2.1239 - val_accuracy: 0.3694\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 2.2322 - accuracy: 0.3400 - val_loss: 2.0041 - val_accuracy: 0.4073\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 2.0541 - accuracy: 0.4450 - val_loss: 1.8749 - val_accuracy: 0.4420\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.6047 - accuracy: 0.5300 - val_loss: 1.5729 - val_accuracy: 0.5096\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.5218 - accuracy: 0.5250 - val_loss: 1.3802 - val_accuracy: 0.5939\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.2016 - accuracy: 0.6350 - val_loss: 1.4243 - val_accuracy: 0.5782\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.0619 - accuracy: 0.6600 - val_loss: 1.0819 - val_accuracy: 0.6914\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.7597 - accuracy: 0.7750 - val_loss: 1.0095 - val_accuracy: 0.7247\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6322 - accuracy: 0.8250 - val_loss: 0.8158 - val_accuracy: 0.7810\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4946 - accuracy: 0.9050 - val_loss: 0.8062 - val_accuracy: 0.7759\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4373 - accuracy: 0.9000 - val_loss: 0.7655 - val_accuracy: 0.7967\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3622 - accuracy: 0.9350 - val_loss: 0.7405 - val_accuracy: 0.8129\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3670 - accuracy: 0.9100 - val_loss: 0.6911 - val_accuracy: 0.8161\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3061 - accuracy: 0.9400 - val_loss: 0.6928 - val_accuracy: 0.8131\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3219 - accuracy: 0.9250 - val_loss: 0.7658 - val_accuracy: 0.8116\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2406 - accuracy: 0.9750 - val_loss: 0.6733 - val_accuracy: 0.8300\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1843 - accuracy: 0.9950 - val_loss: 0.5956 - val_accuracy: 0.8494\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1880 - accuracy: 0.9800 - val_loss: 0.6186 - val_accuracy: 0.8539\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1656 - accuracy: 0.9850 - val_loss: 0.6896 - val_accuracy: 0.8343\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1818 - accuracy: 0.9750 - val_loss: 0.6897 - val_accuracy: 0.8300\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1987 - accuracy: 0.9800 - val_loss: 0.5713 - val_accuracy: 0.8641\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1976 - accuracy: 0.9650 - val_loss: 0.5598 - val_accuracy: 0.8704\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1391 - accuracy: 1.0000 - val_loss: 0.6089 - val_accuracy: 0.8510\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1682 - accuracy: 0.9800 - val_loss: 0.6069 - val_accuracy: 0.8502\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1499 - accuracy: 0.9900 - val_loss: 0.5760 - val_accuracy: 0.8608\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1306 - accuracy: 1.0000 - val_loss: 0.5620 - val_accuracy: 0.8684\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1429 - accuracy: 0.9950 - val_loss: 0.5418 - val_accuracy: 0.8727\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1537 - accuracy: 0.9850 - val_loss: 0.6015 - val_accuracy: 0.8612\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1434 - accuracy: 0.9900 - val_loss: 0.7829 - val_accuracy: 0.8290\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1720 - accuracy: 0.9800 - val_loss: 0.7143 - val_accuracy: 0.8241\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "train_summary = model.fit(x=X_train,\n",
    "                          y=y_train,\n",
    "                          validation_data=(X_val, y_val),\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=num_epochs,\n",
    "                          callbacks=[callback],\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4900/4900 [==============================] - 1s 186us/step\n",
      "\n",
      "Test ACC: 0.833\n"
     ]
    }
   ],
   "source": [
    "# Evaluate fitted model using test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"\\nTest ACC:\", round(test_acc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as plotly_train_val_Accuracy.html\n"
     ]
    }
   ],
   "source": [
    "# Get epochwise performances\n",
    "train_acc = train_summary.history[\"accuracy\"]\n",
    "val_acc = train_summary.history[\"val_accuracy\"]\n",
    "\n",
    "# Format and store performances per epoch for plotting\n",
    "accs = {epoch: [round(performance[0], 2), round(performance[1], 2)]\n",
    "        for epoch, performance in enumerate(zip(train_acc, val_acc))}\n",
    "\n",
    "# Plot training and validation performance over epochs\n",
    "plot_train_val_performances(accs, \"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save_weights(\"model_weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

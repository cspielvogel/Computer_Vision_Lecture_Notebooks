{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "   #### Computer Vision Winter Semester 2021/2022 by Clemens Spielvogel\n",
    "    \n",
    "In the following code example you will see how the keras ImageDataGenerator can be used for data augmentation. Data augmentation increases the generalization of your model, can be used to handle imbalanced data sets and helps building good models on small amounts of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" # If you want to use TF CPU version while having the GPU version installed\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers, regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.offline as ply\n",
    "import plotly.graph_objs as graphs\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeding random number generators to obtain reproducible results\n",
    "seed_value = 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value) # Resets itself on every use!\n",
    "tf.random.set_seed(seed_value) # tf.set_random_seed(seed_value) on older TF versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    # Load CSV file to pandas data frame\n",
    "    df = pd.read_csv(file_path, header=0)\n",
    "\n",
    "    # Split data frame columns into features and labels\n",
    "    y = df[\"label\"].values\n",
    "    X_flat = df.drop(\"label\", axis=1).values\n",
    "    X = [np.resize(array, (28, 28)) for array in X_flat] # Resize flat vector to 28x28\n",
    "    X = np.array([np.reshape(sample, (sample.shape[0], sample.shape[1], 1)) for sample in X]) # Add color channel\n",
    "    \n",
    "    return X, tf.keras.utils.to_categorical(y) # Labels are returned as one-hot encoded vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_performances(performances, metric=\"Accuracy\", show=True):\n",
    "    \"\"\"Plot training vs. testing accuracy over all epochs. performances is a dictionary mapping epoch numbers\n",
    "       as integers to lists containing training and validation performance (e.g. accuracy).\n",
    "       metric is a string indicating the used performance metric.\"\"\"\n",
    "    x = list(performances.keys())     # Number of epochs\n",
    "    y_train = [i[0] for i in performances.values()]\n",
    "    y_val = [i[1] for i in performances.values()]\n",
    "\n",
    "    trace_train = graphs.Scatter(x=x, y=y_train, name=\"Training\", mode=\"lines+markers\",\n",
    "                                 line=dict(width=4),\n",
    "                                 marker=dict(symbol=\"circle\",\n",
    "                                             size=10))\n",
    "    trace_val = graphs.Scatter(x=x, y=y_val, name=\"Validation\", mode=\"lines+markers\",\n",
    "                                line=dict(width=4),\n",
    "                                marker=dict(symbol=\"circle\",\n",
    "                                            size=10))\n",
    "\n",
    "    layout = graphs.Layout(title=\"Training vs. Validation {}\".format(metric),\n",
    "                           xaxis={\"title\": \"Epoch\"},\n",
    "                           yaxis={\"title\": metric})\n",
    "\n",
    "    fig = graphs.Figure(data=[trace_train, trace_val], layout=layout)\n",
    "    ply.plot(fig, filename=\"plotly_train_val_{}.html\".format(metric), auto_open=show)\n",
    "    print(\"Plot saved as plotly_train_val_{}.html\".format(metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_2DCNN_model(input_shape):\n",
    "    \"\"\"Build architecture of the model\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), input_shape=input_shape,\n",
    "                            activation=\"relu\", padding=\"same\"))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=\"selu\", padding=\"same\"))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=\"selu\", padding=\"same\"))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=\"selu\", padding=\"same\"))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation=\"selu\", padding=\"same\"))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation=\"selu\"))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(32, activation=\"selu\"))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    # Create model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify data location\n",
    "data_dir = r\"Data\\mnist.csv\"\n",
    "\n",
    "# Set hyperparameters\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "dims = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X, y = load_data(data_dir)\n",
    "\n",
    "# Determine split sizes\n",
    "train_size = math.floor(0.02 * len(y)) # ONLY 2 % of the data set is used for training\n",
    "val_size = math.floor(0.475 * len(y))\n",
    "test_size = math.floor(0.475 * len(y))\n",
    "\n",
    "# Create splitted sets\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]\n",
    "X_test, y_test = X[train_size+val_size:], y[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN model\n",
    "model = create_2DCNN_model(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation using Keras' built-in data generator\n",
    "train_generator = ImageDataGenerator(rotation_range=15,\n",
    "                                     zoom_range = 0.1,\n",
    "                                     width_shift_range=2,\n",
    "                                     height_shift_range=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure stopping criterion via early stopping\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=4, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-f20d5e5f9d29>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 7.5360 - accuracy: 0.2050 - val_loss: 2.8821 - val_accuracy: 0.1693\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 2.9707 - accuracy: 0.2150 - val_loss: 2.2453 - val_accuracy: 0.2646\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 1.9624 - accuracy: 0.3200 - val_loss: 1.5330 - val_accuracy: 0.4783\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 1.5668 - accuracy: 0.4350 - val_loss: 1.2167 - val_accuracy: 0.6086\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 1.1694 - accuracy: 0.6000 - val_loss: 0.9029 - val_accuracy: 0.7042\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 0.9844 - accuracy: 0.6700 - val_loss: 0.9087 - val_accuracy: 0.6695\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 0.9113 - accuracy: 0.7000 - val_loss: 0.8886 - val_accuracy: 0.6987\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 0.7595 - accuracy: 0.7500 - val_loss: 0.5524 - val_accuracy: 0.8312\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 0.5356 - accuracy: 0.8150 - val_loss: 0.6330 - val_accuracy: 0.8008\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 0.5543 - accuracy: 0.8100 - val_loss: 0.6752 - val_accuracy: 0.7888\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 0.5438 - accuracy: 0.7950 - val_loss: 0.6557 - val_accuracy: 0.7815\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 0.5821 - accuracy: 0.8150 - val_loss: 0.7373 - val_accuracy: 0.7691\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 0.5184 - accuracy: 0.8200 - val_loss: 0.6402 - val_accuracy: 0.7920\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 0.5467 - accuracy: 0.8450 - val_loss: 0.5585 - val_accuracy: 0.8229\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 0.4765 - accuracy: 0.8300 - val_loss: 0.5635 - val_accuracy: 0.8347\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 0.3500 - accuracy: 0.8750 - val_loss: 0.4043 - val_accuracy: 0.8720\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 0.2661 - accuracy: 0.9250 - val_loss: 0.5345 - val_accuracy: 0.8404\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 0.2935 - accuracy: 0.9000 - val_loss: 0.3081 - val_accuracy: 0.9128\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 0.2231 - accuracy: 0.9200 - val_loss: 0.3177 - val_accuracy: 0.9103\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 0.1530 - accuracy: 0.9450 - val_loss: 0.3807 - val_accuracy: 0.8863\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 0.1977 - accuracy: 0.9200 - val_loss: 0.3053 - val_accuracy: 0.9109\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 0.1408 - accuracy: 0.9500 - val_loss: 0.3007 - val_accuracy: 0.9147\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 0.0916 - accuracy: 0.9800 - val_loss: 0.2978 - val_accuracy: 0.9171\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 0.1161 - accuracy: 0.9700 - val_loss: 0.3540 - val_accuracy: 0.8945\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 0.1056 - accuracy: 0.9550 - val_loss: 0.2875 - val_accuracy: 0.9173\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 0.0948 - accuracy: 0.9700 - val_loss: 0.3316 - val_accuracy: 0.9036\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 0.0573 - accuracy: 0.9850 - val_loss: 0.4131 - val_accuracy: 0.8943\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 0.1223 - accuracy: 0.9650 - val_loss: 0.3755 - val_accuracy: 0.8987\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 0.0864 - accuracy: 0.9750 - val_loss: 0.3172 - val_accuracy: 0.9124\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 0.0596 - accuracy: 0.9850 - val_loss: 0.3543 - val_accuracy: 0.9008\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 0.1088 - accuracy: 0.9700 - val_loss: 0.3638 - val_accuracy: 0.9029\n"
     ]
    }
   ],
   "source": [
    "# Training model while dynamically retrieving the augmented data from the generator\n",
    "train_summary = model.fit_generator(generator=train_generator.flow(X_train, y_train, batch_size=32),\n",
    "                                    validation_data=(X_val, y_val),\n",
    "                                    epochs=num_epochs,\n",
    "                                    callbacks=[callback],\n",
    "                                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 0s 3ms/step - loss: 0.2932 - accuracy: 0.9156\n",
      "\n",
      "Test ACC: 0.916\n"
     ]
    }
   ],
   "source": [
    "# Evaluate fitted model using test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"\\nTest ACC:\", round(test_acc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as plotly_train_val_Accuracy.html\n"
     ]
    }
   ],
   "source": [
    "# Get epochwise performances\n",
    "train_acc = train_summary.history[\"accuracy\"]\n",
    "val_acc = train_summary.history[\"val_accuracy\"]\n",
    "\n",
    "# Format and store performances per epoch for plotting\n",
    "accs = {epoch: [round(performance[0], 2), round(performance[1], 2)]\n",
    "        for epoch, performance in enumerate(zip(train_acc, val_acc))}\n",
    "\n",
    "# Save model\n",
    "model.save_weights(\"model_weights.h5\")\n",
    "\n",
    "# Plot training and validation performance over epochs\n",
    "plot_train_val_performances(accs, \"Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
